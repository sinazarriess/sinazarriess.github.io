---
layout: page
title: Research
permalink: /research/
---

### General thoughts

Language is a great and natural way for humans to communicate. It allows us to quickly say what we want when talking to someone, to formulate complex ideas in long texts, to speak about real and non-real worlds, and to combine what we say with other means of non-verbal communication. While grammatical rules of particular languages constrain to some extent how words and sentences have to be formed, they also leave us with a huge space of possibilities to verbalize our thoughts: how exactly am I going to formulate what I want to say? What are the words that I am going to use? How much am I going to say? These decisions are typically not governed by the grammar of a language, but speakers do flexibly adjust them to particular situations, contexts, audiences. The general goal of my work is to model these flexible, communicative aspects of language use, by building machines that model text and dialogue.

I am particularly interested in:

* machine learning methods in natural language generation, both for text and dialogue
* combining natural language analysis and generation
* reference and referring expression (generation)
* multimodal semantics and its connection to reference
* visual language grounding
* conversational aspects of spoken language and their modeling (e.g. hesitations, installments)

### Best paper awards

* a paper on modeling the use of colour terms in real-world image corpora, at INLG 2016 <a class="citation" href="/publications.html#zarriess-schlangen:2016:INLG">(Zarrieß &amp; Schlangen, 2016)</a>
* a paper on conversational time-buying in task-oriented dialogue, at SigDial 2017, <a class="citation" href="/publications.html#lopezgambino-zarriess-schlangen:2017:W17-55">(López Gambino, Zarrieß, &amp; Schlangen, 2017)</a>
* a paper on trainable decoding for neural referring expression generation at INLG 2018 <a class="citation" href="/publications.html#zarriess-schlangen-2018-decoding">(Zarrieß &amp; Schlangen, 2018)</a>

### Current interests
